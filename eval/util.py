from dataclasses import dataclass, field
from pathlib import Path
from typing import Optional, Dict, Any
from synth.solvers import get_consolidated_solver_config

import hashlib
import re
import json
import subprocess
import time
import tempfile
import shlex

@dataclass(frozen=True)
class Run:
    iteration: int
    timeout: Optional[int]

    def get_id(self):
        return f'timeout-{self.timeout}_{self.iteration:04d}'

    def read_stats(self, stats_file: Path):
        """Read the stats file generated by ran command."""
        raise NotImplementedError()

    def get_cmd(self, stats_file: Path):
        """Run the benchmark command, writing stats to stats_file."""
        raise NotImplementedError()

    def get_results_filename(self, output_dir: Path):
        fingerprint = hashlib.sha1(self.get_cmd('').encode('utf-8')).hexdigest()[:10]
        return output_dir / Path(f'{self.get_id()}_{fingerprint}.json')

    def read_result(self, output_dir: Path):
        results_file = self.get_results_filename(output_dir)
        assert results_file.exists()
        with open(results_file, 'rt') as f:
            return json.load(f)

    def run(self, output_dir: Path):
        ns = 1_000_000_000
        result_file = self.get_results_filename(output_dir)
        with tempfile.NamedTemporaryFile(delete=False, delete_on_close=False) as f:
            cmd = self.get_cmd(f.name)
            args = shlex.split(cmd)
            print(cmd)
            try:
                start = time.perf_counter_ns()
                p = subprocess.run(args, timeout=self.timeout, check=True,
                                   capture_output=True, text=True)
                duration = (time.perf_counter_ns() - start)
                stats = {
                    'status': 'success',
                    'wall_time': duration,
                    'output': p.stdout,
                    'stats': self.read_stats(Path(f.name)),
                }
            except subprocess.TimeoutExpired as e:
                stats = { 'status': 'timeout', 'wall_time': self.timeout * ns }
            except subprocess.CalledProcessError as e:
                print(f'Error running {cmd}: {e.returncode} {e.stderr}')
                return {
                    'status': 'error',
                    'returncode': e.returncode,
                    'stderr': e.stderr
                }
        assert output_dir.exists() and output_dir.is_dir()
        with open(result_file, 'wt') as f:
            json.dump(stats, f, indent=4)
        return stats

    def dispatch(self, pool, output_dir: Path):
        pool.apply_async(self.run, (output_dir, ))

@dataclass(frozen=True)
class SynthRun(Run):
    set: str
    bench: str
    synth: str
    solver: str
    run_opts: Dict[str, Any] = field(default_factory=dict)
    set_opts: Dict[str, Any] = field(default_factory=dict)
    syn_opts: Dict[str, Any] = field(default_factory=dict)

    def get_id(self):
        return f'{self.synth}-{self.solver}-{self.set}-{self.bench}-{super().get_id()}'

    def prepare_opts(opts, prefix=None):
        prefix = f'{prefix}.' if prefix else ''
        for k, v in opts.items():
            if isinstance(v, bool):
                yield f'--{prefix}' + ('' if v else 'no-') + k
            else:
                yield f'--{prefix}{k} {v}'

    def get_args(self):
        global solvers
        run_opts = ' '.join(SynthRun.prepare_opts(self.run_opts))
        set_opts = ' '.join(SynthRun.prepare_opts(self.set_opts, prefix='set'))
        syn_opts = ' '.join(SynthRun.prepare_opts(self.syn_opts, prefix='synth'))
        return f'--tests {self.bench} {run_opts} set:{self.set} {set_opts} synth:{self.synth} {syn_opts} synth.solver:config --synth.solver.name {self.solver}'

    def read_stats(self, stats_file: Path):
        with open(stats_file, 'rt') as f:
            return json.load(f)

    def get_cmd(self, stats_file: Path):
        args = self.get_args()
        return f'python benchmark.py run --stats {stats_file} {args}'

@dataclass(frozen=True)
class Cvc5SygusRun(Run):
    difficulty: int
    bench: int
    bit_width: int = 8
    base_dir: Path = Path('resources/sygus')

    def get_id(self):
        return f'cvc5_sygus_p{self.bench:02d}-d{self.difficulty}-w{self.bit_width}-' + super().get_id()

    def read_stats(self, stats_file: Path):
        return ''

    def get_cmd(self, stats_file: Path):
        cfg = get_consolidated_solver_config()
        assert 'cvc5' in cfg, 'cvc5 not available (maybe path is invalid?)'
        bench = Path(f'hd-{self.bench:02d}-d{self.difficulty}-prog.sl')
        dir   = Path(f'sygus-hd-{self.bit_width}bit')
        file  = self.base_dir / dir / bench
        return f'{cfg['cvc5']['path']} {file}'

class Experiment:
    def get_name(self):
        return self.__class__.__name__

    def get_output_filename(self, output_dir: Path, suffix=''):
        return output_dir / Path(f'{self.get_name()}{suffix}.txt')

    def map(self, f):
        def _map(exp, f):
            match exp:
                case dict():
                    return { k: _map(v, f) for k, v in exp.items() }
                case list():
                    return [ _map(e, f) for e in exp ]
                case Run():
                    return f(exp)
        return _map(self.exp, f)

    def runs(self):
        def _iter(exp):
            match exp:
                case dict():
                    for v in exp.values():
                       yield from _iter(v)
                case list():
                    for e in exp:
                        yield from _iter(e)
                case Run():
                    yield exp
        yield from _iter(self.exp)

    def to_run(self, output_dir: Path):
        for run in self.runs():
            if not run.get_results_filename(output_dir).exists():
                yield run

class ComparisonExperiment(Experiment):
    def evaluate(self, stats_dir: Path, output_dir: Path, width=16):
        output_file = self.get_output_filename(output_dir)
        with open(output_file, 'wt') as f:
            get_wall_time = lambda t: t['wall_time'] / 1_000_000_000
            res = self.map(lambda r: r.read_result(stats_dir))
            heads = [f'{'bench':{width}}'] + list(next(iter(res.values())).keys())
            print(' '.join(f'{h:>{width}}' for h in heads), file=f)
            for bench, competitors in res.items():
                times = [ sum(map(get_wall_time, trials)) / len(trials) for trials in competitors.values() ]
                times = ' '.join(f'{t:>{width}.5f}' for t in times)
                print(f'{bench:{width}} {times}', file=f)