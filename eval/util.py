from collections.abc import Sequence
from dataclasses import dataclass, field
from io import StringIO
from pathlib import Path
from shutil import which
from typing import Any, Callable, Mapping

import hashlib
import json
import subprocess
import time
import tempfile
import shlex

from synth.solvers import get_consolidated_solver_config
from sygus import solution_sizes

@dataclass(frozen=True)
class Run:
    iteration: int
    timeout: int | None

    def get_id(self):
        """Uniquely identify this run."""
        cmd = self.get_cmd('')
        return f'{cmd} {self.timeout} {self.iteration:04d}'

    def get_tag(self):
        """A textual description of this run."""
        return f'{self.get_name()}_{self.iteration}_{self.timeout}'

    def read_stats(self, stats_file: Path):
        """Read the stats file generated by ran command."""
        raise NotImplementedError()

    def get_cmd(self, stats_file: Path):
        """Run the benchmark command, writing stats to stats_file."""
        raise NotImplementedError()

    def get_results_filename(self, output_dir: Path):
        filename = f'{self.get_tag()}-' + hashlib.sha1(self.get_id().encode('utf-8')).hexdigest()
        return output_dir / Path(f'{filename}.json')

    def read_result(self, output_dir: Path):
        results_file = self.get_results_filename(output_dir)
        if results_file.exists():
            with open(results_file, 'rt') as f:
                return json.load(f)
        return None

    def run(self, output_dir: Path):
        ns = 1_000_000_000
        result_file = self.get_results_filename(output_dir)
        with tempfile.NamedTemporaryFile(delete=False, delete_on_close=False) as f:
            cmd = self.get_cmd(f.name)
            args = shlex.split(cmd)
            print(cmd)
            try:
                start = time.perf_counter_ns()
                p = subprocess.run(args, timeout=self.timeout, check=True,
                                   capture_output=True, text=True)
                duration = (time.perf_counter_ns() - start)
                stats = {
                    'cmd': cmd,
                    'tag': self.get_tag(),
                    'status': 'success',
                    'wall_time': duration,
                    'output': p.stdout,
                    'stats': self.read_stats(Path(f.name)),
                }
            except subprocess.TimeoutExpired as e:
                stats = {
                    'cmd': cmd,
                    'tag': self.get_tag(),
                    'status': 'timeout',
                    'wall_time': self.timeout * ns
                }
            except subprocess.CalledProcessError as e:
                print(f'Error running {cmd}: {e.returncode} {e.stderr}')
                return {
                    'status': 'error',
                    'tag': self.get_tag(),
                    'returncode': e.returncode,
                    'stderr': e.stderr
                }
        assert output_dir.exists() and output_dir.is_dir()
        with open(result_file, 'wt') as f:
            json.dump(stats, f, indent=4)
        return stats

    def dispatch(self, pool, output_dir: Path):
        pool.apply_async(self.run, (output_dir, ))

def prepare_opts(opts, prefix=None):
    prefix = f'{prefix}.' if prefix else ''
    for k, v in opts.items():
        if isinstance(v, bool):
            yield f'--{prefix}' + ('' if v else 'no-') + k
        else:
            yield f'--{prefix}{k} {v}'

@dataclass(frozen=True)
class SynthRun(Run):
    set: str
    bench: str
    synth: str
    solver: str
    run_opts: dict[str, Any] = field(default_factory=dict)
    set_opts: dict[str, Any] = field(default_factory=dict)
    syn_opts: dict[str, Any] = field(default_factory=dict)
    extra_tag: str = ''

    def read_stats(self, stats_file: Path):
        with open(stats_file, 'rt') as f:
            return json.load(f)

    def get_name(self):
        return 'bench'

    def get_tag(self):
        return f'{super().get_tag()}_{self.set}_{self.bench}_{self.synth}_{self.solver}_{self.extra_tag}'

    def get_cmd(self, stats_file: Path):
        run_opts = ' '.join(prepare_opts(self.run_opts))
        set_opts = ' '.join(prepare_opts(self.set_opts, prefix='set'))
        syn_opts = ' '.join(prepare_opts(self.syn_opts, prefix='synth'))
        args = f'--tests {self.bench} {run_opts} set:{self.set} {set_opts} synth:{self.synth} {syn_opts} synth.solver:config --synth.solver.name {self.solver}'
        return f'uv run benchmark.py run --stats {stats_file} {args}'

@dataclass(frozen=True)
class SygusRun(Run):
    bench: Path
    flags: str = ''
    synth_flags: str = ''
    name: str = 'sygus'

    def read_stats(self, stats_file: Path):
        with open(stats_file, 'rt') as f:
            return json.load(f)

    def get_name(self):
        return self.name

    def get_tag(self):
        return f'{super().get_tag()}_{self.bench.parts[-1]}'

    def get_cmd(self, stats_file: Path):
        return f'uv run sygus.py synth {self.flags} --stats {stats_file} {self.bench} {' '.join(self.synth_flags)}'

@dataclass(frozen=True)
class Cvc5SygusRun(Run):
    bench: Path

    def read_stats(self, _: Path):
        return ''

    def get_name(self):
        return 'cvc5'

    def get_tag(self):
        return f'{super().get_tag()}_{self.bench.parts[-1]}'

    def get_cmd(self, stats_file: Path):
        cfg = get_consolidated_solver_config('solvers.json')
        assert 'cvc5' in cfg, 'cvc5 not available (maybe path is invalid?)'
        return f'{cfg['cvc5']['path']} {self.bench}'

class Experiment:
    def __init__(self,
                 iterations: int, timeout_in_s: int,
                 benchmarks: Sequence, competitors: Mapping[str, Callable]):
        self.exp = {
            str(b): {
                name: [
                    create_run(i, timeout_in_s, b) for i in range(iterations)
                ]
                for name, create_run in competitors.items()
            } for b in benchmarks
        }

    def get_name(self):
        return self.__class__.__name__

    def map(self, f):
        def _map(exp, f):
            match exp:
                case dict():
                    return { k: _map(v, f) for k, v in exp.items() }
                case list():
                    return [ _map(e, f) for e in exp ]
                case Run():
                    return f(exp)
        return _map(self.exp, f)

    def runs(self):
        def _iter(exp):
            match exp:
                case dict():
                    for v in exp.values():
                       yield from _iter(v)
                case list():
                    for e in exp:
                        yield from _iter(e)
                case Run():
                    yield exp
        yield from _iter(self.exp)

    def to_run(self, output_dir: Path):
        for run in self.runs():
            if not run.get_results_filename(output_dir).exists():
                yield run

    def get_results(self, stats_dir: Path):
        res = self.map(lambda r: r.read_result(stats_dir))
        return res

    def get_aggregated_results(self, stats_dir: Path, aggregate: Callable):
        return {
            bench: {
                competitor: aggregate(trials) for competitor, trials in competitors.items()
            } for bench, competitors in self.get_results(stats_dir).items()
        }

def aggregate_wall_time(trials):
    if trials and all('wall_time' in t for t in trials):
        get_wall_time = lambda t: t['wall_time'] / 1_000_000_000
        return sum(map(get_wall_time, trials)) / len(trials)

def aggregate_result_size(trials):
    # print(trials, trials[0])
    if trials and 'output' in trials[0]:
        return sum(sz for _, sz in solution_sizes(StringIO(trials[0]['output'])))

def format_by_bench_row_competitor_col(file_like, res):
    first_width = max(len(s) for s in res)
    other_width = 16
    heads = list(next(iter(res.values())).keys())
    print(f'{'bench':{first_width}}', ' '.join(f'{h:>{other_width}}' for h in heads), file=file_like)
    for bench, competitors in res.items():
        row = ' '.join(f'{t:>{other_width}.5f}' if t else f'{'None':>{other_width}}' for t in competitors.values())
        print(f'{bench:{first_width}} {row}', file=file_like)