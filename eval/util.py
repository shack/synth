from dataclasses import dataclass, field
from pathlib import Path
from shutil import which
from typing import Any

import hashlib
import json
import subprocess
import time
import tempfile
import shlex

from synth.solvers import get_consolidated_solver_config

@dataclass(frozen=True)
class Run:
    iteration: int
    timeout: int | None

    def get_id(self):
        """Uniquely identify this run."""
        cmd = self.get_cmd('')
        return f'{cmd} {self.timeout} {self.iteration:04d}'

    def get_tag(self):
        """A textual description of this run."""
        return f'{self.iteration}-{self.timeout}'

    def read_stats(self, stats_file: Path):
        """Read the stats file generated by ran command."""
        raise NotImplementedError()

    def get_cmd(self, stats_file: Path):
        """Run the benchmark command, writing stats to stats_file."""
        raise NotImplementedError()

    def get_results_filename(self, output_dir: Path):
        filename = self.get_tag() + hashlib.sha1(self.get_id().encode('utf-8')).hexdigest()
        return output_dir / Path(f'{filename}.json')

    def read_result(self, output_dir: Path):
        results_file = self.get_results_filename(output_dir)
        assert results_file.exists()
        with open(results_file, 'rt') as f:
            return json.load(f)

    def run(self, output_dir: Path):
        ns = 1_000_000_000
        result_file = self.get_results_filename(output_dir)
        with tempfile.NamedTemporaryFile(delete=False, delete_on_close=False) as f:
            cmd = self.get_cmd(f.name)
            args = shlex.split(cmd)
            print(cmd)
            try:
                start = time.perf_counter_ns()
                p = subprocess.run(args, timeout=self.timeout, check=True,
                                   capture_output=True, text=True)
                duration = (time.perf_counter_ns() - start)
                stats = {
                    'cmd': cmd,
                    'tag': self.get_tag(),
                    'status': 'success',
                    'wall_time': duration,
                    'output': p.stdout,
                    'stats': self.read_stats(Path(f.name)),
                }
            except subprocess.TimeoutExpired as e:
                stats = {
                    'cmd': cmd,
                    'tag': self.get_tag(),
                    'status': 'timeout',
                    'wall_time': self.timeout * ns
                }
            except subprocess.CalledProcessError as e:
                print(f'Error running {cmd}: {e.returncode} {e.stderr}')
                return {
                    'status': 'error',
                    'tag': self.get_tag(),
                    'returncode': e.returncode,
                    'stderr': e.stderr
                }
        assert output_dir.exists() and output_dir.is_dir()
        with open(result_file, 'wt') as f:
            json.dump(stats, f, indent=4)
        return stats

    def dispatch(self, pool, output_dir: Path):
        pool.apply_async(self.run, (output_dir, ))

def prepare_opts(opts, prefix=None):
    prefix = f'{prefix}.' if prefix else ''
    for k, v in opts.items():
        if isinstance(v, bool):
            yield f'--{prefix}' + ('' if v else 'no-') + k
        else:
            yield f'--{prefix}{k} {v}'

@dataclass(frozen=True)
class SynthRun(Run):
    set: str
    bench: str
    synth: str
    solver: str
    run_opts: dict[str, Any] = field(default_factory=dict)
    set_opts: dict[str, Any] = field(default_factory=dict)
    syn_opts: dict[str, Any] = field(default_factory=dict)
    extra_tag: str = ''

    def read_stats(self, stats_file: Path):
        with open(stats_file, 'rt') as f:
            return json.load(f)

    def get_tag(self):
        return f'bench-{self.set}-{self.bench}-{self.synth}-{self.solver}-{self.extra_tag}-{super().get_tag()}'

    def get_cmd(self, stats_file: Path):
        run_opts = ' '.join(prepare_opts(self.run_opts))
        set_opts = ' '.join(prepare_opts(self.set_opts, prefix='set'))
        syn_opts = ' '.join(prepare_opts(self.syn_opts, prefix='synth'))
        args = f'--tests {self.bench} {run_opts} set:{self.set} {set_opts} synth:{self.synth} {syn_opts} synth.solver:config --synth.solver.name {self.solver}'
        return f'python benchmark.py run --stats {stats_file} {args}'

@dataclass(frozen=True)
class DownscaleRun(Run):
    set: str
    bench: str
    solver: str
    run_opts: dict[str, Any] = field(default_factory=dict)
    set_opts: dict[str, Any] = field(default_factory=dict)

    def read_stats(self, stats_file: Path):
        with open(stats_file, 'rt') as f:
            return json.load(f)

    def get_tag(self):
        return f'downscale-{self.set}-{self.bench}-{self.solver}-{super().get_tag()}'

    def get_cmd(self, stats_file: Path):
        run_opts = ' '.join(prepare_opts(self.run_opts))
        set_opts = ' '.join(prepare_opts(self.set_opts, prefix='set'))
        args = f'--tests {self.bench} {run_opts} set:{self.set} {set_opts} synth:downscale synth.base:len-cegis synth.base.solver:config --synth.base.solver.name {self.solver}'
        return f'python benchmark.py run --stats {stats_file} {args}'


@dataclass(frozen=True)
class SygusRun(Run):
    bench: Path
    flags: str = ''
    synth: str = 'synth:len-cegis'
    synth_flags: str = ''

    def read_stats(self, stats_file: Path):
        with open(stats_file, 'rt') as f:
            return json.load(f)

    def get_tag(self):
        return f'sygus-{self.bench.parts[-1]}-{super().get_tag()}'

    def get_cmd(self, stats_file: Path):
        return f'python sygus.py run {self.flags} --stats {stats_file} {self.synth} {self.synth_flags} {self.bench}'

@dataclass(frozen=True)
class Cvc5SygusRun(Run):
    bench: Path

    def read_stats(self, _: Path):
        return ''

    def get_tag(self):
        return f'cvc5-sygus-{self.bench.parts[-1]}-{super().get_tag()}'

    def get_cmd(self, stats_file: Path):

        cfg = get_consolidated_solver_config('solvers.json')
        assert 'cvc5' in cfg, 'cvc5 not available (maybe path is invalid?)'
        return f'{cfg['cvc5']['path']} {self.bench}'

@dataclass(frozen=True)
class Cvc5SygusBitVecRun(Run):
    difficulty: int
    bench: int
    bit_width: int = 8
    base_dir: Path = Path('resources/sygus')

    def read_stats(self, stats_file: Path):
        return ''

    def get_tag(self):
        return f'cvc5-sygus-bv-{self.bench}-{super().get_tag()}'

    def get_cmd(self, stats_file: Path):
        cfg   = get_consolidated_solver_config('solvers.json')
        assert 'cvc5' in cfg, 'cvc5 not available (maybe path is invalid?)'
        cmd   = cfg['cvc5']['path']
        bench = Path(f'hd-{self.bench:02d}-d{self.difficulty}-prog.sl')
        dir   = Path(f'sygus-hd-{self.bit_width}bit')
        file  = self.base_dir / dir / bench
        return f'{cmd} {file}'

class Experiment:
    def get_name(self):
        return self.__class__.__name__

    def get_output_filename(self, output_dir: Path, suffix=''):
        return output_dir / Path(f'{self.get_name()}{suffix}.txt')

    def map(self, f):
        def _map(exp, f):
            match exp:
                case dict():
                    return { k: _map(v, f) for k, v in exp.items() }
                case list():
                    return [ _map(e, f) for e in exp ]
                case Run():
                    return f(exp)
        return _map(self.exp, f)

    def runs(self):
        def _iter(exp):
            match exp:
                case dict():
                    for v in exp.values():
                       yield from _iter(v)
                case list():
                    for e in exp:
                        yield from _iter(e)
                case Run():
                    yield exp
        yield from _iter(self.exp)

    def to_run(self, output_dir: Path):
        for run in self.runs():
            if not run.get_results_filename(output_dir).exists():
                yield run

class ComparisonExperiment(Experiment):
    def evaluate(self, stats_dir: Path, output_dir: Path, width=16):
        output_file = self.get_output_filename(output_dir)
        with open(output_file, 'wt') as f:
            get_wall_time = lambda t: t['wall_time'] / 1_000_000_000
            res = self.map(lambda r: r.read_result(stats_dir))
            heads = [f'{'bench':{width}}'] + list(next(iter(res.values())).keys())
            print(' '.join(f'{h:>{width}}' for h in heads), file=f)
            for bench, competitors in res.items():
                times = [ sum(map(get_wall_time, trials)) / len(trials) for trials in competitors.values() ]
                times = ' '.join(f'{t:>{width}.5f}' for t in times)
                print(f'{bench:{width}} {times}', file=f)